---
title: "PRR_power_sim_two_way_int"
author: "Hanna Schleihauf"
date: "8/27/2021"
output: html_document
---
---
  title: "PRR power analysis - binomial GLMM"
author: "Hanna Schleihauf"
date: "28/07/2020"
output: 
  html_document:
  theme: united
toc: yes
toc_depth: 4
toc_float: yes
---
  
  ```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(dplyr)
library(cowplot)
#library("gghalves")
source("/Users/HannaSchleihauf/Dropbox/Research/EVAClass/Functions/drop1_para.r")
```
## Download needed packages
```{r}
library(lme4)
library(kyotil) # we want to store info about convergence issues
```

## Generate data
```{r echo=FALSE, include=FALSE}
set.seed(1)
n.subject <- 180 # number subjects

n.per.subject <- 6 # observations per subject
n.condition <- 3 # number of conditions
n.per.condition <- 2 # observations per subject and condition
subj.id <- as.factor(paste("subj", 1:n.subject, sep = "."))

per.outcome.only.4.5 <- 0.2 # performance outcome only for 4-5-year-old children
per.outcome.only.6.7 <- 0.2 # performance outcome only for 6-7-year-old children
per.outcome.only.adults <- 0.1 # performance outcome only for adults
per.process.only.4.5 <- 0.7 # performance process only for 4-5-year-old children
per.process.only.6.7 <- 0.8 # performance process only for 6-7-year-old children
per.process.only.adults <- 0.9 # performance process only for adults
per.process.outcome.4.5 <- 0.3 # performance process vs. outcome for 4-5-year-old children
per.process.outcome.6.7 <- 0.7 # performance process vs. outcome for 6-7-year-old children
per.process.outcome.adults <- 0.8 # performance process vs. outcome for adults

start.data <- data.frame(subj.id)
# duplicate rows according to the number obs. per subject:
start.data <- start.data[rep(x = 1:nrow(start.data), times = n.per.subject), ]
start.data <- as.data.frame(start.data)
names(start.data) <- "subj.id"

# add condition and trial number
start.data <- data.frame(expand.grid(subj.id = subj.id, condition = c(".outcome.only", ".process.only", ".outcome.process"), trial.per.condition = c(1:n.per.condition)))

# add culture
start.data$culture <- as.factor(rep(x = c(".US", ".China"), times = n.subject / 2))[as.numeric(start.data$subj.id)]
# add age group
start.data$age.group <- as.factor(rep(x = c(".4.5", ".6.7", ".adults"), times = n.subject / 3))[as.numeric(start.data$subj.id)]
#add sex
start.data <- start.data[order(start.data$culture, start.data$subj.id),]
start.data$gender <- as.factor(rep(x = c(".male", ".female"), times = n.subject / 2))
# add trial number
start.data$trial <- as.factor(rep(seq(from = 1, to = 6), times = n.subject))

#check whether it worked
ftable(condition ~ age.group + culture +gender, start.data)/2 #should be 30 participants per group

# z-transformation of covariates
start.data$z.trial <- as.vector(scale(as.numeric(start.data$trial)))
start.data$z.trial.per.condition <- as.vector(scale(as.numeric(start.data$trial.per.condition)))

# dummy code factors and center them for random slopes
start.data$condition.process.only <- as.numeric(start.data$condition == levels(start.data$condition)[2])
start.data$condition.outcome.process <- as.numeric(start.data$condition == levels(start.data$condition)[3])
start.data$condition.process.only.c = as.numeric(start.data$condition.process.only)-mean(as.numeric(start.data$condition.process.only)) #centering
start.data$condition.outcome.process.c = start.data$condition.outcome.process-mean(start.data$condition.outcome.process) #centering

start.data$culture.US <- as.numeric(start.data$culture == levels(start.data$culture)[2])
start.data$culture.US.c = start.data$culture.US-mean(start.data$culture.US) #centering

start.data$age.group.6.7 <- as.numeric(start.data$age.group == levels(start.data$age.group)[2])
start.data$age.group.adults <- as.numeric(start.data$age.group == levels(start.data$age.group)[3])
start.data$age.group.6.7.c = start.data$age.group.6.7-mean(start.data$age.group.6.7) #centering
start.data$age.group.adults.c = start.data$age.group.adults-mean(start.data$age.group.adults) #centering

start.data$gender.male <- as.numeric(start.data$gender == levels(start.data$gender)[2])
start.data$gender.male.c = start.data$gender.male-mean(start.data$gender.male) 

# checks:
# does each subject have only one sex and age?
xx <- table(start.data$subj.id, start.data$gender)
range(apply(X = xx > 0, MARGIN = 1, sum)) # should be 1 and 1

xx <- table(start.data$subj.id, start.data$age.group)
range(apply(X = xx > 0, MARGIN = 1, sum)) # should be 1 and 1

xx <- table(start.data$subj.id, start.data$condition)
range(apply(X = xx > 0, MARGIN = 1, sum))

xx <- table(start.data$subj.id, start.data$trial)
range(apply(X = xx > 0, MARGIN = 1, sum))
```

## Simulation
```{r eval=FALSE, include=FALSE}
n.simus <- 10 # small number for testing
r.effects <- c(0.2, 0.4, 0.8) # random effects to be simulated
# with the intercept being -0.8472979 (qlogis(per.outcome.only.4.5)) we could make the following
# guesses for the random intercept:
#- 0.2: tiny random intercepts effect
#- 0.4: moderate random intercepts effect
#- 0.8: strong random intercepts effect
#- 1.6: very strong random intercepts effect

r.slope.process.only <- c(0.4, 0.8)
# with the slope being 1.694596 (qlogis(per.process.only.4.5) - qlogis(per.outcome.only.4.5)) we could make the following
# guesses for the random slope:
#- 0.4: tiny random slope effect
#- 0.8: moderate random slope effect
#- 1.6: strong random slope effect
#- 3.2: very strong random slope effect

r.slope.outcome.process <- c(0.125, 0.25)
# with the slope being 0.5 (qlogis(per.process.outcome.4.5) - qlogis(per.outcome.only.4.5)) we could make the following
# guesses for the random slope:
#- 0.125: tiny random slope effect
#- 0.25: moderate random slope effect
#- 0.5: strong random slope effect
#- 1: very strong random slope effect

r.slope.trial <- 0.1
# create object to store the simulation parameters and results:
all.res <- data.frame(expand.grid(
  n.per.subject = n.per.subject, r.effect = r.effects, 
  r.slope.process.only = r.slope.process.only, r.slope.outcome.process = r.slope.outcome.process, r.slope.trial = r.slope.trial,
  simu = 1:n.simus
))

all.res$icpt <- NA
all.res$condition.process.only <- NA
all.res$condition.outcome.process <- NA
all.res$age.group.6.7 <- NA
all.res$age.group.adults <- NA
all.res$culture.US <- NA
all.res$gender.male <- NA

all.res$condition.process.only.age.group.6.7 <-  NA
all.res$condition.outcome.process.age.group.6.7 <- NA
all.res$condition.process.only.age.group.adults <- NA
all.res$condition.outcome.process.age.group.adults <- NA

all.res$re.sd <- NA
all.res$warns.full <- NA
all.res$warns.null <- NA

all.res$lrt.p.condition <- NA
all.res$lrt.p.age.group <- NA
all.res$lrt.p.culture <- NA
all.res$lrt.p.condition.age.group <- NA
all.res$full.null.p <- NA

# define control structure to make convergence more likely:
contr <- glmerControl(optimizer = "bobyqa", optCtrl = list(maxfun = 10000))

xdata <- start.data

m.mat <- model.matrix(object = ~ condition*age.group + culture + gender, data = xdata) # create model martix

coefs <- c(
  "(Intercept)" = qlogis(per.outcome.only.4.5),
  "condition.process.only" = qlogis(per.process.only.4.5) - qlogis(per.outcome.only.4.5),
  "condition.outcome.process" = qlogis(per.process.outcome.4.5) - qlogis(per.outcome.only.4.5),
  "age.group.6.7" = qlogis(per.outcome.only.6.7) - qlogis(per.outcome.only.4.5),
  "age.group.adults" = qlogis(per.outcome.only.adults) - qlogis(per.outcome.only.4.5),
  "culture.US" = 0,
  "gender.male" = 0,
  "condition.process.only:age.group.6.7" = qlogis(per.process.only.6.7) - 
    (qlogis(per.outcome.only.4.5) + #"intercept"
       (qlogis(per.process.only.4.5) - qlogis(per.outcome.only.4.5)) + #"condition.process.only"
       (qlogis(per.outcome.only.6.7) - qlogis(per.outcome.only.4.5))), #"age.group.6.7"
  "condition.outcome.process:age.group.6.7" = qlogis(per.process.outcome.6.7) - 
    (qlogis(per.outcome.only.4.5) + #"intercept"
       (qlogis(per.process.outcome.4.5) - qlogis(per.outcome.only.4.5)) + #"condition.outcome.process"
       (qlogis(per.outcome.only.6.7) - qlogis(per.outcome.only.4.5))), #"age.group.6.7"
  "condition.process.only:age.group.adults" = qlogis(per.process.only.adults) -
    (qlogis(per.outcome.only.4.5) + #"intercept"
       (qlogis(per.process.only.4.5) - qlogis(per.outcome.only.4.5)) + #"condition.process.only"
       (qlogis(per.outcome.only.adults) - qlogis(per.outcome.only.4.5))), #"age.group.adults"
  "condition.outcome.process:age.group.adults" = qlogis(per.process.outcome.adults) - 
    (qlogis(per.outcome.only.4.5) + #"intercept"
       (qlogis(per.process.outcome.4.5) - qlogis(per.outcome.only.4.5)) + #"condition.outcome.process"
       (qlogis(per.outcome.only.adults) - qlogis(per.outcome.only.4.5))) #"age.group.adults"
)

LP <- m.mat[, names(coefs)] %*% coefs # LP wrt fixed effects

# run simulation
for (i in 1:nrow(all.res)) {
  set.seed(i) # allows to later replicate individual simulations
  
  # add random effect to linear predictor:
  LP <- LP + rnorm(n = n.subject, sd = all.res[i, "r.effect"])[as.numeric(xdata$subj.id)] +
    rnorm(n = n.subject, sd = all.res[i, "r.slope.process.only"])[as.numeric(xdata$subj.id)] * xdata$condition.process.only +
    rnorm(n = n.subject, sd = all.res[i, "r.slope.outcome.process"])[as.numeric(xdata$subj.id)] * xdata$condition.outcome.process +
    rnorm(n = n.subject, sd = all.res[i, "r.slope.trial"])[as.numeric(xdata$subj.id)] * xdata$z.trial 
  
  # generate response:
  xdata$coding <- rbinom(n = nrow(xdata), size = 1, prob = exp(LP) / (1 + exp(LP)))
  
  # fit full model:
  full <- keepWarnings(glmer(coding ~ condition*age.group + culture + gender + (1 + (condition.process.only.c + condition.outcome.process.c) + z.trial || subj.id),
                             data = xdata, family = binomial, control = contr
  ))
  
  # fit null model:
  null <- keepWarnings(glmer(coding ~ gender + (1 + (condition.process.only.c + condition.outcome.process.c) + z.trial || subj.id),
                             data = xdata, family = binomial, control = contr
  ))
  
  red <- keepWarnings(glmer(coding ~ (condition+age.group+culture) + gender + (1 + (condition.process.only.c + condition.outcome.process.c) + z.trial || subj.id),
                             data = xdata, family = binomial, control = contr
  ))
  
  # store results:
  all.res[i, c("icpt", "condition.process.only", "condition.outcome.process", "age.group.6.7", "age.group.adults", "culture.US", "gender.male", "condition.process.only.age.group.6.7", "condition.outcome.process.age.group.6.7", "condition.process.only.age.group.adults", "condition.outcome.process.age.group.adults")] <- fixef(full$value)
  all.res[i, "re.sd"] <- as.data.frame(summary(full$value)$varcor)[1, "sdcor"]
  all.res[i, "warns.full"] <- nchar(paste(full$warnings, collapse = ""))
  all.res[i, "warns.null"] <- nchar(paste(null$warnings, collapse = ""))
  all.res[i, "full.null.p"] <- as.data.frame(anova(null$value, full$value, test = "Chisq"))[2, "Pr(>Chisq)"]

  all.res[i, "lrt.p.condition.age.group"] <- as.data.frame(drop1(full$value, test = "Chisq"))["condition:age.group", "Pr(Chi)"]
  
  xx = drop1(red$value, test = "Chisq")
  all.res[i, "lrt.p.condition"] <- as.data.frame(xx)["condition", "Pr(Chi)"]
  all.res[i, "lrt.p.age.group"] <- as.data.frame(xx)["age.group", "Pr(Chi)"]
  all.res[i, "lrt.p.culture"] <- as.data.frame(xx)["culture", "Pr(Chi)"]
  }

#save.image("power.simulation.with.two.way.int.RData")
```

## Evaluation of results 
```{r echo=FALSE}
load("power.simulation.with.two.way.int.RData")
```

#number of warning per combinations of random effects (out of 1000 models per cell)  

Full model:
```{r echo=FALSE}
#full model
tapply(X=all.res[, "warns.full"]>0, INDEX=all.res[, c("r.slope.process.only", "r.slope.outcome.process", "r.effect")],
       FUN=sum)
#warning codes: 
#363: unable to evaluate scaled gradient. Model failed to converge: degenerate  Hessian with 1 negative eigenvalues
#205: Model is nearly unidentifiable: large eigenvalue ratio - Rescale variables?
```

Null model:  
```{r echo=FALSE}
#null model: 
tapply(X=all.res[, "warns.null"]>0, INDEX=all.res[, c("r.slope.process.only", "r.slope.outcome.process", "r.effect")],
       FUN=sum)
```

* plotting the estimates (all models)

```{r echo=FALSE}
par(mar=c(3, 3, 0.2, 0.2), mgp=c(1.7, 0.3, 0), tcl=-0.15, las=1)
plot(
  x = as.numeric(as.factor(rep(
    x = c("icpt", "conditiontest", "re.sd"),
    each = nrow(all.res)
  ))),
  y = unlist(all.res[, c("icpt", "conditiontest", "re.sd")]),
  pch = 19, col = grey(level = 0.2, alpha = 0.2),
  xaxt = "n", xlim = c(0.5, 3.5), ylab = "estimate", xlab = ""
)
mtext(text = c("icpt", "conditiontest", "re.sd"), side = 1, at = 1:3, line = 0.2)
```

## Only models that converged are evaluated from here on:  

```{r include=FALSE}
all.res2=subset(all.res, warns.full==0)

table(round(all.res2$conditiontest))

```

### How many models converged and have a significant LRT of condition or a significant full-null model comparison?   
```{r echo=FALSE}
lrt.data <- all.res2 %>%
  group_by(test.per, r.effect, r.slope.con) %>%
  summarise(lrt.p.con.mean = mean(lrt.p.con), #mean condition p-value of the models that converged
            n.sign.lrt = length(lrt.p.con[lrt.p.con < 0.05]), #number of significant condition effects
            n.lrt = n.simus,#length(lrt.p.con), #number of iterations
            proportion.sign.lrt = length(lrt.p.con[lrt.p.con < 0.05]) / n.simus, #proportion of significant condition effects
            full.null.p.mean = mean(full.null.p), #mean full-null model p-value of the models that converged
            n.sign.full.null.p = length(full.null.p[full.null.p < 0.05]), #number of significant full-null model comparisons
            n.fn = n.simus, #length(full.null.p), #number of iterations 
            proportion.sign.fn = length(full.null.p[full.null.p < 0.05]) /n.simus) #proportion of significant full-null model comparisons

lrt.data
```

#### Plotting the proportion of significant Full-null model comparisons

```{r echo=FALSE}

ggplot(data = lrt.data, aes(y=proportion.sign.fn))+
  geom_point(aes(x=as.factor(r.effect), y=proportion.sign.fn))+
  geom_boxplot(aes(x=as.factor(r.effect), y=proportion.sign.fn, group=r.effect))+
  #theme_classic()+
  ylim(0.3, 1)+
  geom_hline(yintercept=0.8, colour="red", lty=2)+
  facet_wrap(~r.slope.con)

```



#### Plotting the proportion of significant LRTs for the predictor variable condition

```{r echo=FALSE}

ggplot(data = lrt.data, aes(y=proportion.sign.lrt))+
  geom_point(aes(x=as.factor(r.effect), y=proportion.sign.lrt))+
  geom_boxplot(aes(x=as.factor(r.effect), y=proportion.sign.lrt, group=r.effect))+
  #theme_classic()+
  ylim(0.3, 1)+
  geom_hline(yintercept=0.8, colour="red", lty=2)+
  facet_wrap(~r.slope.con)

```

### How many models converged, have a significant full-null model comparison, and a significant LRT of condition?  
```{r echo=FALSE}

lrt.data2 <- all.res2 %>%
  filter(full.null.p<0.05)%>%
  group_by(test.per, r.effect, r.slope.con) %>%
  summarise(lrt.p.con.mean2 = mean(lrt.p.con), 
            n.sign.lrt2 = length(lrt.p.con[lrt.p.con < 0.05]), 
            n.lrt = n.simus,#length(lrt.p.con), 
            proportion.sign.lrt2 = length(lrt.p.con[lrt.p.con < 0.05]) / n.simus)

lrt.data2
```

#### Plotting the proportion of significant LRTs for the predictor variable condition ONLY based on models that converged and with a significant full-null model comparison

```{r echo=FALSE}

p.con.power <- ggplot(data = lrt.data2, aes(y=proportion.sign.lrt2))+
  geom_boxplot(data = lrt.data2 %>% filter(r.slope.con == "0.45"), aes(x=as.factor(r.effect), y=proportion.sign.lrt2, group=as.factor(r.effect)), position = position_nudge(x = -.15), col = "darkorange", width=0.3)+
  geom_boxplot(data = lrt.data2 %>% filter(r.slope.con == "0.9"), aes(x=as.factor(r.effect), y=proportion.sign.lrt2, group=as.factor(r.effect)), position = position_nudge(x = .15), col = "dodgerblue", width=0.3)+
  ylim(0.0, 1)+
  geom_hline(yintercept = 0.8, colour = "black", lwd = 1.05, lty = 3) +
  facet_wrap(~test.per)+
  ylab("Power") +
  xlab("Size of random effect") +
  theme_bw()
p.con.power

#ggsave(p, filename = "GLMM_w_condition_power.png", scale = 0.5, height = 8, width = 12)
```

#### Plotting the intercepts
```{r echo=FALSE}
#some preparation for plotting:
par(mar=c(3, 3, 0.2, 0.2), mgp=c(1.7, 0.3, 0), tcl=-0.15, las=1)
where=as.numeric(as.factor(paste(all.res2$r.effect, all.res2$r.slope.con,
                                 sep="_")))

plot(x=where, y=all.res2$icpt, xlab="", xaxt="n", pch=19,
     col=grey(level=0.5, alpha=0.5), cex=1.5)
abline(h=coefs["(Intercept)"])
mtext(text=rep(x=r.slope.con, times=length(r.effects)), side=1, line=0.2,
      at=1:(length(r.effects)*length(r.slope.con)), cex=1)
mtext(text="r.slope", side=1, line=0.2, at=0.5, cex=1)
mtext(text=rep(x=r.effects, each=length(r.slope.con)), side=1, line=1.4,
      at=1:(length(r.effects)*length(r.slope.con)), cex=1)
mtext(text="re:", side=1, line=1.4, at=0.5, cex=1)
abline(v=(1:length(r.effects))[-length(r.effects)]*length(r.slope.con)+0.5,
       lty=2)
```

```{r echo=FALSE}
ggplot(data = all.res2, aes(x=as.factor(r.effect), y=icpt))+
  geom_jitter( alpha=0.5, col="grey")+
  geom_boxplot(aes(x=as.factor(r.effect), y=icpt, group=r.effect), alpha=0.1, outlier.colour="white")+
  geom_hline(yintercept=coefs["(Intercept)"], colour="red", lty=2)+
  facet_wrap(~r.slope.con)
```



#### Plotting the fixed effect of condition
```{r echo=FALSE}

plot(x=where, y=all.res2$conditiontest, xlab="", xaxt="n", pch=19,
     col=grey(level=0.5, alpha=0.5), cex=1.5)
abline(h=coefs["conditiontest"])
mtext(text=rep(x=r.slope.con, times=length(r.effects)), side=1, line=0.2,
      at=1:(length(r.effects)*length(r.slope.con)), cex=1)
mtext(text="r.slope", side=1, line=0.2, at=0.5, cex=1)
mtext(text=rep(x=r.effects, each=length(r.slope.con)), side=1, line=1.4,
      at=1:(length(r.effects)*length(r.slope.con)), cex=1)
mtext(text="re:", side=1, line=1.4, at=0.5, cex=1)
abline(v=(1:length(r.effects))[-length(r.effects)]*length(r.slope.con)+0.5,
       lty=2)
```

```{r echo=FALSE}
p.con.est <- ggplot(data = all.res2, aes(x = as.factor(r.effect), y = conditiontest)) +
  geom_jitter(data = all.res2, aes(x = as.factor(r.effect), y = conditiontest, color = as.factor(r.slope.con)), size = 1.5, position = position_jitterdodge(dodge.width = 0.8, jitter.width = 0.5), alpha = .1) +
  scale_color_manual(values = c("darkorange", "dodgerblue"), name = "Random slopes") +
  geom_boxplot(data = all.res2 %>% filter(r.slope.con == "0.45"), aes(x = as.factor(r.effect), y = conditiontest, group = as.factor(r.effect)), position = position_nudge(x = -.2), width = 0.3, alpha = 0.1, outlier.colour = "white") +
  geom_boxplot(data = all.res2 %>% filter(r.slope.con == "0.9"), aes(x = as.factor(r.effect), y = conditiontest, group = as.factor(r.effect)), position = position_nudge(x = .2), width = 0.3, alpha = 0.1, outlier.colour = "white") +
  facet_wrap(~test.per) +
  geom_hline(yintercept = 0, colour = "black", alpha = 0.5) +
  geom_hline(data = data.frame(test.per = "0.65"), aes(yintercept = coefs["conditiontest"]), colour = "red", lwd = 1.05, lty = 2, alpha = 0.7) +
  geom_hline(data = data.frame(test.per = "0.55"), aes(yintercept = qlogis(0.55) - qlogis(1 / 3)), colour = "red", lwd = 1.05, lty = 2, alpha = 0.7) +
  ylab("Condition fixed effect") +
  xlab("Size of random intercept") +
  theme_bw() +
  theme(legend.position = "none")

p.legend <- ggplot(data = all.res2 %>% mutate(r.slope.con = fct_recode(as.factor(r.slope.con), "medium" = "0.45", "large" = "0.9")), aes(x = as.factor(r.effect), y = conditiontest)) +
  geom_point(aes(colour = as.factor(r.slope.con))) +
  scale_color_manual(values = c("darkorange", "dodgerblue"), name = "Random slope") +
  theme_classic() +
  theme(legend.direction = "horizontal", legend.box.background = element_rect(colour = "black"))

p.leg <- get_legend(p.legend)

p.con <- plot_grid(p.con.power, p.con.est, labels = c("a", "b"), rel_widths = c(1, 1))
p.con2 <- ggdraw(plot_grid(p.con, p.leg, ncol = 1, nrow = 2, rel_heights = c(1, 0.15)))
ggsave(p.con2, filename = "Exp3_condition_model.png", scale = 0.5, height = 9, width = 16)
```


#### Plotting the random intercept  
```{r echo=FALSE}
plot(x=where, y=all.res2$re.sd, xlab="", xaxt="n", pch=19,
     col=grey(level=0.5, alpha=0.5), cex=1.5)
hll=1.0
where2=((1:length(r.effects))-1)*length(r.slope.con)+1.5
segments(x0=where2-hll, x1=where2+hll, y0=r.effects, y1=r.effects)
mtext(text=rep(x=r.slope.con, times=length(r.effects)), side=1, line=0.2,
      at=1:(length(r.effects)*length(r.slope.con)), cex=1)
mtext(text="r.slope", side=1, line=0.2, at=0.5, cex=1)
mtext(text=rep(x=r.effects, each=length(r.slope.con)), side=1, line=1.4,
      at=1:(length(r.effects)*length(r.slope.con)), cex=1)
mtext(text="re:", side=1, line=1.4, at=0.5, cex=1)
abline(v=(1:length(r.effects))[-length(r.effects)]*length(r.slope.con)+0.5,
       lty=2)
```


```{r echo=FALSE}
ggplot(data = all.res2, aes(x=as.factor(r.effect), y=re.sd))+
  geom_jitter( alpha=0.5, col="grey")+
  geom_boxplot(aes(x=as.factor(r.effect), y=re.sd, group=r.effect), alpha=0.1, outlier.colour="white")+
  #theme_classic()+
  #scale_y_continuous(trans='log10')+
  #geom_hline(yintercept=0.05, colour="red", lty=2)+
  facet_wrap(~r.slope.con)
```


#### Plotting the full-null model comparison p-values
```{r echo=FALSE}
ggplot(data = all.res2, aes(y=full.null.p))+
  geom_jitter(aes(x=as.factor(r.effect), y=full.null.p), alpha=0.5, col="grey")+
  geom_boxplot(aes(x=as.factor(r.effect), y=full.null.p, group=r.effect), alpha=0.1, outlier.colour="white")+
  #theme_classic()+
  scale_y_continuous(trans='log10')+
  geom_hline(yintercept=0.05, colour="red", lty=2)+
  facet_wrap(~r.slope.con)

```

#### Plotting the LRT p-values of condition
```{r echo=FALSE}
ggplot(data = all.res2, aes(y=lrt.p.con))+
  geom_jitter(aes(x=as.factor(r.effect), y=lrt.p.con), alpha=0.5, col="grey")+
  geom_boxplot(aes(x=as.factor(r.effect), y=lrt.p.con, group=r.effect), alpha=0.1, outlier.colour="white")+
  #theme_classic()+
  scale_y_continuous(trans='log10')+
  geom_hline(yintercept=0.05, colour="red", lty=2)+
  facet_wrap(~r.slope.con)

```


write.table(xdata, "PRR.mock.data.txt",quote=FALSE, col.names = T, sep = "\t")


